{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import get_latex_table, compute_accuracies\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_repetitions = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image features and labels\n",
    "image_features = torch.load(\"../data/cars196/image_features.pt\")\n",
    "df = pd.read_csv(\"../data/cars196/Cars196.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use the test images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 8054\n",
    "image_features = {i: item for i, item in image_features.items() if i > cutoff}\n",
    "df = df[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_features = [image_features[i] for i in sorted(image_features.keys())]\n",
    "image_features = torch.tensor(np.stack(image_features, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8131, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class_index</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>8055</td>\n",
       "      <td>FIAT 500 Abarth 2012</td>\n",
       "      <td>98</td>\n",
       "      <td>FIAT</td>\n",
       "      <td>500 Abarth</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>2012</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8055</th>\n",
       "      <td>8056</td>\n",
       "      <td>FIAT 500 Abarth 2012</td>\n",
       "      <td>98</td>\n",
       "      <td>FIAT</td>\n",
       "      <td>500 Abarth</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>2012</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8056</th>\n",
       "      <td>8057</td>\n",
       "      <td>FIAT 500 Abarth 2012</td>\n",
       "      <td>98</td>\n",
       "      <td>FIAT</td>\n",
       "      <td>500 Abarth</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>2012</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8057</th>\n",
       "      <td>8058</td>\n",
       "      <td>FIAT 500 Abarth 2012</td>\n",
       "      <td>98</td>\n",
       "      <td>FIAT</td>\n",
       "      <td>500 Abarth</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>2012</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8058</th>\n",
       "      <td>8059</td>\n",
       "      <td>FIAT 500 Abarth 2012</td>\n",
       "      <td>98</td>\n",
       "      <td>FIAT</td>\n",
       "      <td>500 Abarth</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>2012</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16180</th>\n",
       "      <td>16181</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>195</td>\n",
       "      <td>smart</td>\n",
       "      <td>fortwo</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>2012</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16181</th>\n",
       "      <td>16182</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>195</td>\n",
       "      <td>smart</td>\n",
       "      <td>fortwo</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>2012</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16182</th>\n",
       "      <td>16183</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>195</td>\n",
       "      <td>smart</td>\n",
       "      <td>fortwo</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>2012</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16183</th>\n",
       "      <td>16184</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>195</td>\n",
       "      <td>smart</td>\n",
       "      <td>fortwo</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>2012</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16184</th>\n",
       "      <td>16185</td>\n",
       "      <td>smart fortwo Convertible 2012</td>\n",
       "      <td>195</td>\n",
       "      <td>smart</td>\n",
       "      <td>fortwo</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>2012</td>\n",
       "      <td>silver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8131 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       img_name                     class_name  class_index manufacturer  \\\n",
       "8054       8055           FIAT 500 Abarth 2012           98         FIAT   \n",
       "8055       8056           FIAT 500 Abarth 2012           98         FIAT   \n",
       "8056       8057           FIAT 500 Abarth 2012           98         FIAT   \n",
       "8057       8058           FIAT 500 Abarth 2012           98         FIAT   \n",
       "8058       8059           FIAT 500 Abarth 2012           98         FIAT   \n",
       "...         ...                            ...          ...          ...   \n",
       "16180     16181  smart fortwo Convertible 2012          195        smart   \n",
       "16181     16182  smart fortwo Convertible 2012          195        smart   \n",
       "16182     16183  smart fortwo Convertible 2012          195        smart   \n",
       "16183     16184  smart fortwo Convertible 2012          195        smart   \n",
       "16184     16185  smart fortwo Convertible 2012          195        smart   \n",
       "\n",
       "            model         type  year   color  \n",
       "8054   500 Abarth    Hatchback  2012   black  \n",
       "8055   500 Abarth    Hatchback  2012   black  \n",
       "8056   500 Abarth    Hatchback  2012   black  \n",
       "8057   500 Abarth    Hatchback  2012   black  \n",
       "8058   500 Abarth    Hatchback  2012   black  \n",
       "...           ...          ...   ...     ...  \n",
       "16180      fortwo  Convertible  2012   black  \n",
       "16181      fortwo  Convertible  2012   other  \n",
       "16182      fortwo  Convertible  2012     red  \n",
       "16183      fortwo  Convertible  2012   white  \n",
       "16184      fortwo  Convertible  2012  silver  \n",
       "\n",
       "[8131 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scrapes all car model names from the kbb page\n",
    "# car_models = pd.read_html(\"https://www.kbb.com/car-make-model-list/new/view-all/make/\")\n",
    "# all_models = car_models[0][\"Make\"] + \" \" + car_models[0][\".css-z687n{margin:10px 24px 10px 0px;}Model\"]\n",
    "# all_models = all_models.dropna().tolist()\n",
    "# all_models = list(set(all_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(all_models, \"../data/cars196/all_models_scraped_kbb_2022-08-17.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = torch.load(\"../data/cars196/all_models_scraped_kbb_2022-08-17.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_samples = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "number_samples = [110, 120, 130, 140, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 Samples; Run 1\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (1745): 0.010866930708289146: : 1745it [00:12, 135.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.008945324458181858) achieved after 1645 iterations.\n",
      "110 Samples; Run 2\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (1520): 0.011797674000263214: : 1520it [00:12, 118.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.010914814658463001) achieved after 1420 iterations.\n",
      "110 Samples; Run 3\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (1358): 0.012299204245209694: : 1358it [00:17, 78.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.010449138469994068) achieved after 1258 iterations.\n",
      "110 Samples; Run 4\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (1302): 0.01239329669624567: : 1302it [00:10, 125.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.011103208176791668) achieved after 1202 iterations.\n",
      "110 Samples; Run 5\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (1197): 0.012469707056879997: : 1197it [00:08, 134.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.012230615131556988) achieved after 1097 iterations.\n",
      "120 Samples; Run 1\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (1248): 0.014585975557565689: : 1248it [00:09, 130.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.01337459310889244) achieved after 1148 iterations.\n",
      "120 Samples; Run 2\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (2052): 0.01163273025304079: : 2052it [00:20, 100.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.0103429164737463) achieved after 1952 iterations.\n",
      "120 Samples; Run 3\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (2595): 0.01134711317718029: : 2595it [00:26, 96.18it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.010093646124005318) achieved after 2495 iterations.\n",
      "120 Samples; Run 4\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (1518): 0.0110417939722538: : 1518it [00:13, 109.61it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.010892817750573158) achieved after 1418 iterations.\n",
      "120 Samples; Run 5\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (1687): 0.012092257849872112: : 1687it [00:14, 113.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.011334397830069065) achieved after 1587 iterations.\n",
      "130 Samples; Run 1\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (2370): 0.012716713361442089: : 2370it [00:27, 86.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.011775221675634384) achieved after 2270 iterations.\n",
      "130 Samples; Run 2\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (1843): 0.014571169391274452: : 1843it [00:24, 74.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.014345630072057247) achieved after 1743 iterations.\n",
      "130 Samples; Run 3\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (1848): 0.015455317683517933: : 1848it [00:22, 81.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.013896002434194088) achieved after 1748 iterations.\n",
      "130 Samples; Run 4\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (1690): 0.016017742455005646: : 1690it [00:13, 128.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.015314096584916115) achieved after 1590 iterations.\n",
      "130 Samples; Run 5\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (1413): 0.015868328511714935: : 1413it [00:10, 139.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.015044826082885265) achieved after 1313 iterations.\n",
      "140 Samples; Run 1\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (2685): 0.017380202189087868: : 2685it [00:22, 119.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.016968613490462303) achieved after 2585 iterations.\n",
      "140 Samples; Run 2\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (2853): 0.01715206541121006: : 2853it [00:24, 116.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.01681957021355629) achieved after 2753 iterations.\n",
      "140 Samples; Run 3\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (1681): 0.019832907244563103: : 1681it [00:18, 89.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.019431505352258682) achieved after 1581 iterations.\n",
      "140 Samples; Run 4\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (2795): 0.01850137673318386: : 2795it [00:28, 96.79it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.0184063371270895) achieved after 2695 iterations.\n",
      "140 Samples; Run 5\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (2421): 0.018231680616736412: : 2421it [00:23, 102.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.017495816573500633) achieved after 2321 iterations.\n",
      "150 Samples; Run 1\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (2643): 0.022859107702970505: : 2643it [00:24, 107.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.02268695831298828) achieved after 2543 iterations.\n",
      "150 Samples; Run 2\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (2811): 0.02330043725669384: : 2811it [00:20, 135.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.022672148421406746) achieved after 2711 iterations.\n",
      "150 Samples; Run 3\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (3161): 0.023913681507110596: : 3161it [00:26, 118.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.02364715002477169) achieved after 3061 iterations.\n",
      "150 Samples; Run 4\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (2865): 0.02200642041862011: : 2865it [00:28, 101.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.021673500537872314) achieved after 2765 iterations.\n",
      "150 Samples; Run 5\n",
      "Creating text features\n",
      "Getting optimized CLIP performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss (2864): 0.024194661527872086: : 2864it [00:42, 67.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimization. Best loss (0.02401668392121792) achieved after 2764 iterations.\n"
     ]
    }
   ],
   "source": [
    "labels = df[\"class_name\"].tolist()\n",
    "\n",
    "for num_samples in number_samples:\n",
    "    model_samples = []\n",
    "    results_dfs = []\n",
    "    for i in range(num_repetitions):\n",
    "        model_sample = np.random.choice(all_models, num_samples, replace=False)\n",
    "        model_samples.append(model_sample)\n",
    "        texts = [f\"a photo of a {m}\" for m in model_sample]\n",
    "\n",
    "        print(f\"{num_samples} Samples; Run {i+1}\")\n",
    "        results = compute_accuracies(image_features, labels, texts, num_components=128, include_models=[\"ours\"])\n",
    "        results_dfs.append(results)\n",
    "\n",
    "    results_mean = sum(results_dfs) / len(results_dfs)\n",
    "    results_std = np.sqrt(sum([(df - results_mean)**2 for df in results_dfs]) / len(results_dfs))\n",
    "\n",
    "    torch.save({\n",
    "        \"num_samples\": num_samples,\n",
    "        \"model_samples\": model_samples,\n",
    "        \"means\": results_mean,\n",
    "        \"stds\": results_std\n",
    "    }, f\"prompt_analysis_results/{num_samples}_samples.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "plt.style.use(['science'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5, 2.625]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 252x189 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 252x86.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_to_name = {\n",
    "    \"\\model\": \"CLIP-DML\",\n",
    "    \"Rand. transform\": \"Rand. trans.\"\n",
    "}\n",
    "\n",
    "files = glob(f\"prompt_analysis_results/*_samples.pt\")\n",
    "data = [torch.load(f) for f in files]\n",
    "data = sorted(data, key=lambda x: x[\"num_samples\"])\n",
    "\n",
    "metric = \"mean_average_precision_at_r\"\n",
    "model = \"\\model\"\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(3.5, 1.2))\n",
    "\n",
    "\n",
    "x = np.array([d[\"num_samples\"] for d in data])\n",
    "means = np.array([d[\"means\"][model][metric] for d in data])\n",
    "stds = np.array([d[\"stds\"][model][metric] for d in data])\n",
    "\n",
    "plt.errorbar(x, means, yerr=stds, label=model_to_name.get(model, model))\n",
    "\n",
    "plt.xticks(x, rotation=45)\n",
    "# plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Number of prompts\")\n",
    "plt.ylabel(\"MAP@R\")\n",
    "\n",
    "plt.savefig(f\"prompt_analysis_results/cars196.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdc694a4c29a8e83627f4fb3f10aa377f3d41a22792e193fc551a811e775afaf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
